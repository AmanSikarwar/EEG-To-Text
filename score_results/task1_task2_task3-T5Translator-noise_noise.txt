corpus_bleu_score = [0.15541740827381714, 0.05215208590090656, 0.01698614926310098, 0.006746281325257439]
sacre_blue_score = {'score': 0.47255302517728837, 'counts': [4159, 241, 30, 5], 'totals': [22559, 21361, 20163, 18965], 'precisions': [18.43610089099694, 1.1282243340667573, 0.14878738282993603, 0.026364355391510677], 'bp': 0.8841757462172192, 'sys_len': 22559, 'ref_len': 25336}
rouge_scores = {'rouge-1': {'r': 0.1148254527600671, 'p': 0.12232798642276585, 'f': 0.11101770497573793}, 'rouge-2': {'r': 0.01001490118309575, 'p': 0.011005081951735171, 'f': 0.009744312859357833}, 'rouge-l': {'r': 0.10003643419427344, 'p': 0.10455481082717988, 'f': 0.09561846352521168}}
wer_scores = 1.1174235403151065
cer_scores = 0.8658036510212782
corpus_bleu_score_with_tf = [0.4363009040383001, 0.25571345218552877, 0.15229259272219378, 0.08784440144727948]
sacre_blue_score_with_tf = {'score': 4.771429499616451, 'counts': [8732, 2078, 518, 166], 'totals': [23640, 22442, 21244, 20046], 'precisions': [36.93739424703892, 9.259424293734961, 2.438335530032009, 0.8280953806245634], 'bp': 0.9307702509488945, 'sys_len': 23640, 'ref_len': 25336}
rouge_scores_with_tf = {'rouge-1': {'r': 0.23363295044286245, 'p': 0.28399061824485766, 'f': 0.2544708864675091}, 'rouge-2': {'r': 0.05327729251656549, 'p': 0.06004010037424964, 'f': 0.05606838958391259}, 'rouge-l': {'r': 0.21675969170986384, 'p': 0.2628107513510377, 'f': 0.2358341233130569}}
wer_scores_with_tf = 0.8146431881371641
cer_scores_with_tf = 0.6203558001627844
